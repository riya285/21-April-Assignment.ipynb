{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5227d99-2f77-43e9-ba0e-f1f463ac3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Main difference between Euclidean and Manhattan distance in KNN:\n",
    "\n",
    "Euclidean Distance: Measures the straight-line distance between two points in Euclidean space. It is the square root of the sum of squared differences between corresponding coordinates.\n",
    "\n",
    "Manhattan Distance: Also known as the L1 norm or taxicab distance, it measures the sum of absolute differences between corresponding coordinates.\n",
    "\n",
    "The main difference lies in how distance is calculated. Euclidean distance considers the overall spatial difference, whereas Manhattan distance is based on the sum of individual differences along each dimension. The impact on KNN performance depends on the data distribution; in cases where features are equally important, Manhattan distance might be more suitable.\n",
    "\n",
    "Q2. Choosing the optimal value of k:\n",
    "\n",
    "Techniques for choosing k include:\n",
    "Cross-validation: Evaluate the model's performance for different k values using cross-validation and choose the one with the best performance.\n",
    "Grid Search: Systematically test a range of k values and choose the one with the best performance.\n",
    "Domain Knowledge: Consider the nature of the problem and the characteristics of the data to inform the choice of k.\n",
    "\n",
    "Q3. Effect of distance metric choice on KNN performance:\n",
    "\n",
    "The choice of distance metric can significantly affect KNN performance.\n",
    "Euclidean distance works well when features are on similar scales, while Manhattan distance is less sensitive to differences in scale.\n",
    "Euclidean distance may be more suitable for cases where the relationships between features are more important.\n",
    "\n",
    "Q4. Common hyperparameters in KNN and their impact:\n",
    "\n",
    "k: Number of neighbors to consider. Larger values of k provide a smoother decision boundary but might oversmooth.\n",
    "Weights: Determine how the contribution of neighbors is weighted. Options include uniform weighting or weighting by the inverse of the distance.\n",
    "Distance Metric: Choice between Euclidean, Manhattan, etc.\n",
    "Algorithm: KNN supports different algorithms, such as 'ball_tree' or 'kd_tree'. The choice may depend on the dataset size.\n",
    "Tuning involves experimenting with different values and assessing their impact on model performance using techniques like cross-validation.\n",
    "\n",
    "Q5. Effect of training set size on KNN performance:\n",
    "\n",
    "Large Training Set: Can improve model generalization but increases computation time.\n",
    "Small Training Set: May lead to overfitting, especially in high-dimensional spaces.\n",
    "Optimizing the training set size involves finding a balance that minimizes overfitting without sacrificing the model's ability to capture underlying patterns.\n",
    "\n",
    "Q6. Potential drawbacks of KNN as a classifier or regressor:\n",
    "\n",
    "Computational Cost: KNN can be computationally expensive, especially with large datasets.\n",
    "Sensitive to Noise and Outliers: Noisy or outlier-prone data can impact predictions.\n",
    "Curse of Dimensionality: Performance can degrade in high-dimensional spaces.\n",
    "Imbalanced Data: KNN may not perform well with imbalanced class distributions.\n",
    "To overcome these drawbacks, techniques such as dimensionality reduction, feature scaling, outlier handling, and data preprocessing can be employed. Additionally, careful consideration of hyperparameters is essential.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
